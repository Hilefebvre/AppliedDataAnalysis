{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing goals:**<br>\n",
    "In the second part of the project we aimed to familiarize with our dataset and explore its possibilities in order to decide what trends we want to extract out of it. As mentioned before, we first take into account the archives of both the Gazette de Lausanne (GDL) and the Journal de Genève (JDG) during the XXth century. It restricts our dataset to a 100 years for both our journals. Now, we want to study the evolution of environnemental causes interests in the public space. Therefore, we are in a first part going to estimate this evolution and the eventual rises in society awareness on the topics related to these causes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing pipeline (Part 1):**<br>\n",
    "We wanted to set up a basic pipeline in order to get a better view of what our dataset can offer and decide afterwards in which directions we could go on with our work. The below detailed pipeline is exectued for each journal separately.\n",
    "- First, we extract all the archives from the XXth century of both our journals. Theses archives are xml files. We are therefore going to use the Beautiful Soup html parser to get a sense of what it contains. \n",
    "- From our own exploration of the dataset, we saw that all the articles had the following tags coming along: `name` to charaterize the title of the article, `issue_date` to indicate the date when the article was released in the journal and `full_text` with the article corpus . Thus, we are again going to use Beautiful Soup methods. Here, `find_all` will help us retrieve all the content of the previously mentioned tags that matter to our analysis. \n",
    "\n",
    "- Once that their content is retrieved in a dictionnary we use the text attribute to put the names and issue dates of all articles in a list, that we then convert as a pandas dataframe.\n",
    "\n",
    "- We `pickle` the result, such that we won't have to process this extraction step everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths to the data of both journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_GDL = 'data/GDL/'\n",
    "DATA_FOLDER_JDG = 'data/JDG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving of all folders of both journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_gdl = os.listdir(DATA_FOLDER_GDL)\n",
    "listing_jdg = os.listdir(DATA_FOLDER_JDG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get rid of the 17th and 18th centuries folders as well as of hidden folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefixes = ('17', '18','190','191','192','193','194','195','196','197','198','1991','1992','1993','1994','1995','1996','1997','1998','1999','.')\n",
    "prefixes = ('17', '18','.')\n",
    "for dir_ in listing_gdl[:]:\n",
    "    if dir_.startswith(prefixes):\n",
    "        listing_gdl.remove(dir_)\n",
    "        \n",
    "for dir_ in listing_jdg[:]:\n",
    "    if dir_.startswith(prefixes):\n",
    "        listing_jdg.remove(dir_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we go over all xml files for the 20th century data and store in the two separate lists (issue dates and names) the extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(data_folder, listing, journal):\n",
    "    print(\"Function get_articles()\")\n",
    "    list_articles = []\n",
    "\n",
    "    for infile in listing : \n",
    "        sublisting = os.listdir(data_folder + infile)\n",
    "        for insubfile in sublisting:\n",
    "            display(infile +'/'+ insubfile);\n",
    "            file = open(data_folder + infile + '/' +insubfile, encoding='utf-8')\n",
    "            page = file.read()\n",
    "\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            all_articles_name = soup.find_all('name')\n",
    "            all_articles_date = soup.find_all('issue_date')\n",
    "            all_articles_content = soup.find_all('full_text')\n",
    "\n",
    "            for i in range(len(all_articles_date)):\n",
    "                article_crt = {'Article title ({})'.format(journal) : all_articles_name[i].text,\n",
    "                              'Issue date ({})'.format(journal) : all_articles_date[i].text,\n",
    "                              'Article content ({})'.format(journal) : all_articles_content[i].text}\n",
    "\n",
    "                list_articles.append(article_crt)\n",
    "\n",
    "    df_articles = pd.DataFrame.from_dict(list_articles)\n",
    "    \n",
    "    print(\"End function get_articles()\")\n",
    "    \n",
    "    return df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file inexistant\n",
      "Function get_articles()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1902/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/08.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/09.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/10.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/11.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/12.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/08.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/09.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/10.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/11.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df_jdg = pd.read_pickle('data_serialized/articles_jdg.pickle')\n",
    "    print(\"Recuperation données in pickle file\")\n",
    "except (OSError, IOError) as e:\n",
    "    print(\"Pickle file inexistant\")\n",
    "    df_jdg = get_articles(data_folder = DATA_FOLDER_JDG, listing = listing_jdg, journal = \"JDG\")\n",
    "    df_jdg.to_pickle('data_serialized/articles_jdg.pickle')\n",
    "    \n",
    "df_jdg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file inexistant\n",
      "Function get_articles()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1900/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/08.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/09.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/10.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/11.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1900/12.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/08.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/09.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/10.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/11.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1901/12.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/08.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/09.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/10.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/11.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1902/12.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/08.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/09.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/10.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/11.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1903/12.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/01.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/02.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/03.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/04.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/05.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/06.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1904/07.xml'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df_gdl = pd.read_pickle('data_serialized/articles_gdl.pickle')\n",
    "    print(\"Recuperation données in pickle file\")\n",
    "except (OSError, IOError) as e:\n",
    "    print(\"Pickle file inexistant\")\n",
    "    df_gdl = get_articles(data_folder = DATA_FOLDER_GDL, listing = listing_gdl, journal = 'GDL')\n",
    "#     df_gdl.to_pickle('data_serialized/articles_gdl.pickle')\n",
    "    \n",
    "# df_gdl.head()\n",
    "print(\"EXTRACTION DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gdl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d36e7ac47c0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# df_gdl.to_pickle('data_serialized/articles_gdl.pickle')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_gdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_gdl' is not defined"
     ]
    }
   ],
   "source": [
    "# df_gdl.to_pickle('data_serialized/articles_gdl.pickle')\n",
    "    \n",
    "df_gdl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gdl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5dd76c7706a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_gdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_gdl' is not defined"
     ]
    }
   ],
   "source": [
    "df_gdl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('number of articles (GDL): ', len(df_gdl), '\\nnumber of articles (JDG): ', len(df_jdg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing pipeline (Part 2):**<br>\n",
    "Now that the first part of our analysis is done we want to learn information about the extracted data. \n",
    "- To begin, we are putting each list into a pandas series.\n",
    "- After that, we want to relate issue dates and the title of their related article. So we create 2 dataframes (one for each journal) with two columns: Issue dates and articles names.\n",
    "- The format of the issue dates is propice to convert the related column into the datetime format.\n",
    "\n",
    "And now we are going to proceed with our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with untitled articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdl = df_gdl[~df_gdl['Article title (GDL)'].str.contains(\"Untitled Article\")]\n",
    "\n",
    "df_jdg = df_jdg[~df_jdg['Article title (JDG)'].str.contains(\"Untitled Article\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdl.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_jdg.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jdg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert issue dates column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdl['Issue date (GDL)'] = pd.to_datetime(df_gdl['Issue date (GDL)'], infer_datetime_format = True)\n",
    "\n",
    "df_jdg['Issue date (JDG)'] = pd.to_datetime(df_jdg['Issue date (JDG)'], infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing (Part 3):**<br>\n",
    "- We want to know when the public sphere got interested into the environnement related subjects. Therefore in a very basic manner, we are going to go over all the articles names and see if the terms \"environnement\" and \"écologie\" are making frequent apparitions during the XXth century. It will results in the creation of dataframes with only the rows of articles mentioning theses terms.\n",
    "- We want to get a sense of when these apparitions were and thus we are going to use the value counts method to count the occurence of the terms \"environnement\" and \"écologie\" during the XXth century.\n",
    "- We are also including a merging step to not only see the trends in both journals separetely but to also see their joint occurences.\n",
    "- Finally, we are going to plot histograms of occurences of the terms in regard of the issuing year of the articles to get a visual rendering of these trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_gdl = df_gdl[df_gdl['Article title (GDL)'].str.contains(\"écologie\", case = False) == True]\n",
    "\n",
    "dfEcologie_jdg = df_jdg[df_jdg['Article title (JDG)'].str.contains(\"écologie\", case = False) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_gdl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_jdg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count occurences of the term \"écologie\" in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_gdl_counts = dfEcologie_gdl['Issue Dates (GDL)'].dt.year.value_counts()\n",
    "\n",
    "dfEcologie_jdg_counts = dfEcologie_jdg['Issue Dates (JDG)'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_gdl_counts = dfEcologie_gdl_counts.sort_index()\n",
    "\n",
    "dfEcologie_jdg_counts = dfEcologie_jdg_counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "dfEcologie_gdl_counts.plot(kind=\"bar\")\n",
    "plt.title('Number of occurences of the term \"Ecologie\" in articles name during the 20th century in the GDL')\n",
    "plt.xlabel('Issue year of the article')\n",
    "plt.ylabel('Number of occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "dfEcologie_jdg_counts.plot(kind=\"bar\")\n",
    "plt.title('Number of occurences of the term \"Ecologie\" in articles name during the 20th century in the JDG')\n",
    "plt.xlabel('Issue year of the article')\n",
    "plt.ylabel('Number of occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the GDL and JDG data into one single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_joint = pd.merge(pd.DataFrame(dfEcologie_gdl_counts), pd.DataFrame(dfEcologie_jdg_counts), left_index = True, right_index = True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace non existing values (put by default as NaN) for certain years for one of the journal with 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_joint.fillna(value='0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_joint.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the occurences columns to numeric in order to sum them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEcologie_joint['Issue Dates (GDL)'] = pd.to_numeric(dfEcologie_joint['Issue Dates (GDL)'])\n",
    "dfEcologie_joint['Issue Dates (JDG)'] = pd.to_numeric(dfEcologie_joint['Issue Dates (JDG)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfEcologie_joint = dfEcologie_joint.sum(axis = 1, skipna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "dfEcologie_joint.plot(kind=\"bar\")\n",
    "plt.title('Number of occurences of the term \"Ecologie\" in articles name during the 20th century in the both journals')\n",
    "plt.xlabel('Issue year of the article')\n",
    "plt.ylabel('Number of occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_gdl = df_gdl[df_gdl['Articles Names (GDL)'].str.contains(\"environnement\", case = False) == True]\n",
    "\n",
    "dfEnvironnement_jdg = df_jdg[df_jdg['Articles Names (JDG)'].str.contains(\"environnement\", case = False) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_gdl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_jdg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count occurences of the term \"environnement\" in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_gdl_counts = dfEnvironnement_gdl['Issue Dates (GDL)'].dt.year.value_counts()\n",
    "dfEnvironnement_gdl_counts = dfEnvironnement_gdl_counts.sort_index()\n",
    "\n",
    "dfEnvironnement_jdg_counts = dfEnvironnement_jdg['Issue Dates (JDG)'].dt.year.value_counts()\n",
    "dfEnvironnement_jdg_counts = dfEnvironnement_jdg_counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "dfEnvironnement_gdl_counts.plot(kind=\"bar\")\n",
    "plt.title('Number of occurences of the term \"Environnement\" in articles name during the 20th century in the GDL')\n",
    "plt.xlabel('Issue year of the article')\n",
    "plt.ylabel('Number of occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "dfEnvironnement_jdg_counts.plot(kind=\"bar\")\n",
    "plt.title('Number of occurences of the term \"Environnement\" in articles name during the 20th century in the JDG')\n",
    "plt.xlabel('Issue year of the article')\n",
    "plt.ylabel('Number of occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the GDL and JDG data into one single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_joint = pd.merge(pd.DataFrame(dfEnvironnement_gdl_counts), pd.DataFrame(dfEnvironnement_jdg_counts), left_index = True, right_index = True, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace non existing values (put by default as NaN) for certain years for one of the journal with 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_joint.fillna(value='0', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the occurences columns to numeric in order to sum them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_joint['Issue Dates (GDL)'] = pd.to_numeric(dfEnvironnement_joint['Issue Dates (GDL)'])\n",
    "dfEnvironnement_joint['Issue Dates (JDG)'] = pd.to_numeric(dfEnvironnement_joint['Issue Dates (JDG)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEnvironnement_joint = dfEnvironnement_joint.sum(axis = 1, skipna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "dfEnvironnement_joint.plot(kind=\"bar\")\n",
    "plt.title('Number of occurences of the term \"Environnement\" in articles name during the 20th century in the both journals')\n",
    "plt.xlabel('Issue year of the article')\n",
    "plt.ylabel('Number of occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**<br>\n",
    "- It is very interesting to see that rises in the mentionning of the terms \"environnement\" and \"écologie\" appear at the same time in both journals and it is thereofre accountable in the joint histogram. We clear out two majors peaks around 1987 and 1992 for both terms and both journals. \n",
    "- Other than that, we see that before the 1970s approximatively these terms were inexistant in the journals or at least not explicitely mentionned in the articles titles. It can be a hint for our furhter analysis that most of the work can be done with the data from posterior years to that decade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What comes next:\n",
    "This first pre-processing can not by the few terms examined render perfectly and precisely the information from our data. However, the chosen terms are quite general and can be the most probable to be used. So the observations made can give us serious hints on what to do for the pursuit of our analysis.\n",
    "- One necessary thing to do is to retrieve a set of envrionnemental causes related terms and examine their occurences in the dataset. It will help us determine when the main peaks of information on these related subjects really are.\n",
    "- After that, we have to know more about what these articles talk about and extract information from it. So one important thing to do is, once we have understood when the important years of publication are, we want to build a new set of data with the articles full content. We are then going to use these wholes articles to understand what the really talk about and especially what is the context that makes the journals talk about environnemental causes. Furthermore, we are going to try and learn the kind of tone they use to treat these topics. Is it done in a scaring manner? Preventing manner? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
